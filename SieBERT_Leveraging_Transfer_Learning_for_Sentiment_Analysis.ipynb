{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g6PVv6MEms4"
      },
      "source": [
        "## **SieBERT: Leveraging Transfer Learning for Sentiment Analysis**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6GyNR6-A6zA"
      },
      "outputs": [],
      "source": [
        "# install Hugging Face's transformers and datasets libraries\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vCWGmlOmOOS"
      },
      "outputs": [],
      "source": [
        "# check GPU status\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6RSHQgBE45g"
      },
      "source": [
        "### **Example 1:** Applying SieBERT, a pretrained sentiment analysis model, with *3 lines of code*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZirK3Ik0C8QB"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline  # load pipeline() function from transformers library\n",
        "sentiment_analysis = pipeline(\"sentiment-analysis\", model=\"siebert/sentiment-roberta-large-english\")  # load pretrained SieBERT model (\"Sentiment in English\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOkR1O7vEfxX"
      },
      "outputs": [],
      "source": [
        "sentiment_analysis(\"This is super helpful. I love it!\")  # apply pretrained model to example sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z80LPvk-FY0C"
      },
      "source": [
        "### **Example 2:** Classifying multiple sentences using SieBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLfIbInfBdy9"
      },
      "outputs": [],
      "source": [
        "# load dependencies\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# specify path of pretrained model\n",
        "checkpoint = \"siebert/sentiment-roberta-large-english\"  # SieBERT\n",
        "\n",
        "# load pretrained tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krk8KHqsCO0y"
      },
      "outputs": [],
      "source": [
        "# provide 2 example sentences\n",
        "sequences = [\"This is amazing\", \"I don't think it's useless.\", \"I hate this!\"]\n",
        "\n",
        "# tokenize sequences\n",
        "tokens = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# predict with model\n",
        "output = model(**tokens)\n",
        "\n",
        "# transform logits to class labels\n",
        "predictions = torch.nn.functional.softmax(output.logits, dim=-1)\n",
        "confidences = predictions.max(1)[0].tolist()\n",
        "classes = predictions.argmax(-1).tolist()\n",
        "labels = pd.Series(classes).map(model.config.id2label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6eSAsiBIXyL"
      },
      "outputs": [],
      "source": [
        "# consolidate results\n",
        "df = pd.DataFrame(list(zip(sequences, classes, labels, confidences)), columns=['text', 'class', 'class_label', 'confidence'])\n",
        "\n",
        "# return dataframe\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBq2HQrKL8bV"
      },
      "source": [
        "### **Example 3:** Fine-tuning SieBERT for multi-class sentiment analysis in a different domain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i58V94wL7i-"
      },
      "outputs": [],
      "source": [
        "# load three-class sentiment data set from Hugging Face\n",
        "from datasets import load_dataset\n",
        "sentiment = load_dataset('sentiment140')  # source: https://huggingface.co/datasets/sentiment140/viewer/sentiment140/test\n",
        "print(sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fuw1VTN4QJrH"
      },
      "outputs": [],
      "source": [
        "# print first row from training data split\n",
        "print(sentiment['train'][0])\n",
        "\n",
        "# count number of labels\n",
        "NUM_LABELS = len(set(sentiment['test']['sentiment']))\n",
        "print(set(sentiment['test']['sentiment']))\n",
        "print(NUM_LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkdAqLtdRFcD"
      },
      "outputs": [],
      "source": [
        "# define preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G02WzNB0RbHP"
      },
      "outputs": [],
      "source": [
        "# tokenize dataset\n",
        "tokenized_sentiment = sentiment.map(preprocess_function, batched=True)\n",
        "\n",
        "# use dynamic padding\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ez1_Rvngius"
      },
      "outputs": [],
      "source": [
        "# define evaluation metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkGVHYzQRzi1"
      },
      "outputs": [],
      "source": [
        "# initialize pretrained model with updated classification head\n",
        "model2 = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=NUM_LABELS, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEQGA_MB2HL6"
      },
      "outputs": [],
      "source": [
        "# set number of epochs\n",
        "NUM_EPOCHS = 1\n",
        "NUM_EXAMPLES = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXXmJKo9E43R"
      },
      "outputs": [],
      "source": [
        "# rename label column\n",
        "tokenized_sentiment = tokenized_sentiment.rename_column(\"sentiment\", \"label\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnsIVgYxLqFJ"
      },
      "outputs": [],
      "source": [
        "from datasets import ClassLabel, Value\n",
        "\n",
        "# update labels\n",
        "def update_labels(example):\n",
        "  example['label'] = example['label'] / 2\n",
        "  return example\n",
        "\n",
        "tokenized_sentiment = tokenized_sentiment.map(update_labels)\n",
        "\n",
        "new_features = tokenized_sentiment['test'].features.copy()\n",
        "new_features[\"label\"] = ClassLabel(names=['neg', 'neu', 'pos'])\n",
        "tokenized_sentiment['test'] = tokenized_sentiment['test'].cast(new_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZzEpncFJk72"
      },
      "outputs": [],
      "source": [
        "# check features\n",
        "tokenized_sentiment['test'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5dKnKeATSzv"
      },
      "outputs": [],
      "source": [
        "# train SieBERT\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=NUM_EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model2,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_sentiment[\"test\"].select(range(0,NUM_EXAMPLES)),  \n",
        "    eval_dataset=tokenized_sentiment[\"test\"].select(range(NUM_EXAMPLES,498)),\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjvzWT92xMI"
      },
      "outputs": [],
      "source": [
        "# store evaluations for SieBERT\n",
        "siebert_eval = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTWB6tC67doM"
      },
      "outputs": [],
      "source": [
        "# specify path of pretrained model\n",
        "checkpoint = \"roberta-large\"  # RoBERTa-large\n",
        "\n",
        "# load pretrained tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "# initialize pretrained model with updated classification head\n",
        "model3 = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=NUM_LABELS, ignore_mismatched_sizes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_UeZ8nS3Cb9"
      },
      "outputs": [],
      "source": [
        "# train RoBERTa\n",
        "trainer = Trainer(\n",
        "    model=model3,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_sentiment[\"test\"].select(range(0,NUM_EXAMPLES)),  \n",
        "    eval_dataset=tokenized_sentiment[\"test\"].select(range(NUM_EXAMPLES,498)),\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN1BXFIR3Ttz"
      },
      "outputs": [],
      "source": [
        "# store evaluations for RoBERTa\n",
        "roberta_eval = trainer.evaluate()\n",
        "models = ['SieBERT', 'RoBERTa']\n",
        "accuracies = [siebert_eval['eval_accuracy'], roberta_eval['eval_accuracy']]\n",
        "f1_scores = [siebert_eval['eval_f1'], roberta_eval['eval_f1']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4wLbKB33Vvr"
      },
      "outputs": [],
      "source": [
        "# consolidate results\n",
        "eval = pd.DataFrame(list(zip(models, accuracies, f1_scores)), columns=['model', 'accuracy', 'f1_score'])\n",
        "\n",
        "# return dataframe\n",
        "eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqjgHp_SRH13"
      },
      "source": [
        "Source: https://huggingface.co/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SieBERT: Leveraging Transfer Learning for Sentiment Analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}